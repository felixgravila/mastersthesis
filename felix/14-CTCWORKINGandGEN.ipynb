{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as kb\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Activation, Add, Lambda\n",
    "from tensorflow.keras.layers import Dense, MaxPooling1D, Conv1D, LSTM\n",
    "from tensorflow.keras.backend import ctc_batch_cost\n",
    "import numpy as np\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5000)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_X = np.load(\"train_X.npy\")\n",
    "train_y = np.load(\"train_y.npy\", allow_pickle=True)\n",
    "# test_X  = np.load(\"test_X.npy\")\n",
    "# test_y  = np.load(\"test_y.npy\", allow_pickle=True)\n",
    "\n",
    "print(f\"input shape: {train_X.shape}\")\n",
    "print(train_y.shape)\n",
    "# print(test_X.shape)\n",
    "# print(test_y.shape)\n",
    "\n",
    "train_X_lens = np.array([[97] for x in train_X], dtype=\"float32\")\n",
    "print(f\"input_length shape: {train_X_lens.shape}\")\n",
    "\n",
    "train_y_lens = np.array([[len(x)] for x in train_y], dtype=\"float32\")\n",
    "print(f\"label_length shape: {train_y_lens.shape}\")\n",
    "\n",
    "maxlen = max([len(r) for r in train_y])\n",
    "train_y_padded = np.array([r + [-1]*(maxlen-len(r)) for r in train_y], dtype='float32')\n",
    "print(f\"labels shape: {train_y_padded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {'the_input': train_X,\n",
    "          'the_labels': train_y_padded,\n",
    "          'input_length': train_X_lens,\n",
    "          'label_length': train_y_lens\n",
    "          }\n",
    "outputs = {'ctc': np.zeros([len(train_X)])}  # dummy data for dummy loss function\n",
    "training_data = (inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctc_lambda_func(args):\n",
    "    y_pred, labels, input_length, label_length = args\n",
    "    # the 2 is critical here since the first couple outputs of the RNN\n",
    "    # tend to be garbage:\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    return kb.ctc_batch_cost(\n",
    "        y_true=labels, \n",
    "        y_pred=y_pred, \n",
    "        input_length=input_length, \n",
    "        label_length=label_length\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = Input(name=\"the_input\", shape=(200,1), dtype=\"float32\")\n",
    "inner = Conv1D(32, 3,\n",
    "          padding=\"valid\",\n",
    "          activation=\"relu\",\n",
    "          name=\"conv1d_1\")(input_data)\n",
    "inner = MaxPooling1D(pool_size=2, name=\"maxpool_1\")(inner)\n",
    "lstm_1a = LSTM(100,return_sequences=True, name=\"lstm_1a\")(inner)\n",
    "lstm_1b = LSTM(100, return_sequences=True, go_backwards=True, name=\"lstm_1b\")(inner)\n",
    "lstm_1_merged = Add()([lstm_1a, lstm_1b])\n",
    "\n",
    "inner = Dense(5, name=\"dense_1\")(lstm_1_merged)\n",
    "\n",
    "y_pred = Activation(\"softmax\", name=\"softmax\")(inner)\n",
    "\n",
    "# Model(inputs=input_data, outputs=y_pred).summary()\n",
    "\n",
    "labels = Input(name='the_labels', shape=(maxlen), dtype='float32')\n",
    "input_length = Input(name='input_length', shape=(1), dtype='int64')\n",
    "label_length = Input(name='label_length', shape=(1), dtype='int64')\n",
    "\n",
    "loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n",
    "\n",
    "model = Model(inputs=[input_data, labels, input_length, label_length], outputs=loss_out, name=\"my_model\")\n",
    "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer='adam')\n",
    "\n",
    "# model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=inputs, y=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['the_input'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(inputs['the_input'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 100\n",
    "\n",
    "def testgen(train_X, train_y, train_X_lens, train_y_lens, batchsize):\n",
    "    i = 0\n",
    "    while i + batchsize < len(train_X):\n",
    "        inputs = {'the_input': train_X[i:i+batchsize],\n",
    "          'the_labels': train_y_padded[i:i+batchsize],\n",
    "          'input_length': train_X_lens[i:i+batchsize],\n",
    "          'label_length': train_y_lens[i:i+batchsize]\n",
    "          }\n",
    "        outputs = {'ctc': np.zeros([batchsize])}\n",
    "        i+=batchsize\n",
    "        yield (inputs, outputs)\n",
    "\n",
    "model.fit_generator(generator=testgen(train_X, train_y, train_X_lens, train_y_lens, batchsize), steps_per_epoch=(len(train_X)//batchsize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = testgen(train_X, train_y, train_X_lens, train_y_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = next(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generated[0]['the_labels'][0]) # list of length $max_string_length with the string\n",
    "print(generated[0]['label_length'][0]) # single element noting the length of the label\n",
    "im0 = generated[0]['the_input'][0]\n",
    "print(im0.shape)\n",
    "print(im0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
